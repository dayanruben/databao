name: ollama:gpt-oss:20b

max_tokens: 32768
temperature: 0.8
timeout: 600

# Refer to https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html
model_kwargs:
  reasoning: medium
  num_ctx: 131072  # Override the global context size: https://docs.ollama.com/context-length
  num_predict: 32768

  # Sampling params (from LM Studio)
  repeat_penalty: 1.1
  top_k: 40
  top_p: 0.8

  validate_model_on_init: true
